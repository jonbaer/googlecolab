{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creative-writing-gpt2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonbaer/googlecolab/blob/master/creative_writing_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb6Xo3Or8bRz",
        "colab_type": "text"
      },
      "source": [
        "# Cloning the creative writing code base\n",
        "\n",
        "This copies the code & data required onto the Colab notebook instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkW9GVWGb07F",
        "colab_type": "code",
        "outputId": "f30e57a7-481a-45a8-aadf-9e51befb866d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!rm -rf /content/creative-writing-with-gpt2\n",
        "!git clone https://github.com/ADGEfficiency/creative-writing-with-gpt2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'creative-writing-with-gpt2'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 104 (delta 30), reused 96 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 30.10 MiB | 19.73 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wflq6aRh8jqo",
        "colab_type": "text"
      },
      "source": [
        "# Installing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXCaLAob2xj",
        "colab_type": "code",
        "outputId": "ca4afee5-ca41-4839-ce06-56192e4a8d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "!pip install -q -r /content/creative-writing-with-gpt2/requirements.txt\n",
        "print(' ')\n",
        "print('finished installing packages')\n",
        "\n",
        "import os \n",
        "os.makedirs('/content/creative-writing-with-gpt2/models', exist_ok=True)\n",
        "\n",
        "#  silence tensorflow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('INFO')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.4MB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 87.9MB 86kB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 58.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 35.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 74.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 675kB 68.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 67.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 860kB 58.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
            "\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            " \n",
            "finished installing packages\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU7iRBi2A2Qz",
        "colab_type": "text"
      },
      "source": [
        "# Available raw data\n",
        "\n",
        "The creative writing code base has a few clean datasets included, which can be used for fine-tuning.  You can see the text using the *Files* browser on the right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj3XPNvmA2bM",
        "colab_type": "code",
        "outputId": "d1ff8a5a-9127-4b44-f080-35502f742b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print('Available datasets:')\n",
        "!ls /content/creative-writing-with-gpt2/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available datasets:\n",
            "alan-watts  bible  hemingway  meditations  tolkien\n",
            "asimov\t    harry  mahabarta  plato\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ9jXNCi9qyz",
        "colab_type": "text"
      },
      "source": [
        "# Downloading pretrained models\n",
        "\n",
        "Because the size of the pretrained models is massive, I've made them available as shared links on my Google Drive.  \n",
        "\n",
        "The code below will download them to this instance of the Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpVeQ2Zc5OJ",
        "colab_type": "code",
        "outputId": "64955adb-ea1e-471e-9e94-ae538d929753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "%cd /content/creative-writing-with-gpt2/\n",
        "from models import models, download_pretrained_model\n",
        "%cd /content/\n",
        "\n",
        "print(' ')\n",
        "print('Available pre-finetuned models:')\n",
        "for k in models.keys():\n",
        "  print(k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/creative-writing-with-gpt2\n",
            "/content\n",
            " \n",
            "Available pre-finetuned models:\n",
            "alan-watts\n",
            "bible\n",
            "harry\n",
            "meditations\n",
            "tolkien\n",
            "asimov\n",
            "hemingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M84nfFOmEub",
        "colab_type": "code",
        "outputId": "55a05942-57e0-4555-8c6d-2844d2f849bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "download_pretrained_model('tolkien', prefix='/content/creative-writing-with-gpt2')\n",
        "download_pretrained_model('bible', prefix='/content/creative-writing-with-gpt2')\n",
        "download_pretrained_model('harry', prefix='/content/creative-writing-with-gpt2')\n",
        "download_pretrained_model('asimov', prefix='/content/creative-writing-with-gpt2')\n",
        "download_pretrained_model('meditations', prefix='/content/creative-writing-with-gpt2')\n",
        "\n",
        "!ls /content/creative-writing-with-gpt2/models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading tolkien\n",
            "Downloading 1-0lq9cGClSqcvcI3WqGkxdmAdoWrhD4e into /content/creative-writing-with-gpt2/models/tolkien.zip... Done.\n",
            "Unzipping...Done.\n",
            "downloading bible\n",
            "Downloading 1x8SQgqZyLGRdHRV6BUIHEPxZuWUCyhRc into /content/creative-writing-with-gpt2/models/bible.zip... Done.\n",
            "Unzipping...Done.\n",
            "downloading harry\n",
            "Downloading 1-3iQhw89Biyv1QMf4o2BEahoPX9g3fNd into /content/creative-writing-with-gpt2/models/harry.zip... Done.\n",
            "Unzipping...Done.\n",
            "downloading asimov\n",
            "Downloading 1yg4bORU_KpV4h_aVnbMaekulK6ShpCS1 into /content/creative-writing-with-gpt2/models/asimov.zip... Done.\n",
            "Unzipping...Done.\n",
            "downloading meditations\n",
            "Downloading 1-9TiibA0_dqD7dqyJnBNBrZnLuegAa_E into /content/creative-writing-with-gpt2/models/meditations.zip... Done.\n",
            "Unzipping...Done.\n",
            "asimov\t    bible      harry\t  meditations\t   tolkien\n",
            "asimov.zip  bible.zip  harry.zip  meditations.zip  tolkien.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JehZsN6M9_0f",
        "colab_type": "text"
      },
      "source": [
        "## Using a finetuned model\n",
        "\n",
        "This can be run after either downloading a model or training your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G_PcK2a9-5C",
        "colab_type": "code",
        "outputId": "f63aaf0c-8960-4ccb-96de-220571d15792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['MODELNAME'] = 'tolkien'  # change this to use a different model\n",
        "!python /content/creative-writing-with-gpt2/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=\"/content/creative-writing-with-gpt2/models/$MODELNAME\" \\\n",
        "--length=50  # determines the amount of characters to output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   Model name '/content/creative-writing-with-gpt2/models/tolkien' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). Assuming '/content/creative-writing-with-gpt2/models/tolkien' is a path or url to a directory containing tokenizer files.\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   loading file /content/creative-writing-with-gpt2/models/tolkien/vocab.json\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   loading file /content/creative-writing-with-gpt2/models/tolkien/merges.txt\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   loading file /content/creative-writing-with-gpt2/models/tolkien/added_tokens.json\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   loading file /content/creative-writing-with-gpt2/models/tolkien/special_tokens_map.json\n",
            "12/14/2019 17:05:54 - INFO - transformers.tokenization_utils -   loading file /content/creative-writing-with-gpt2/models/tolkien/tokenizer_config.json\n",
            "12/14/2019 17:05:54 - INFO - transformers.configuration_utils -   loading configuration file /content/creative-writing-with-gpt2/models/tolkien/config.json\n",
            "12/14/2019 17:05:54 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "12/14/2019 17:05:54 - INFO - transformers.modeling_utils -   loading weights file /content/creative-writing-with-gpt2/models/tolkien/pytorch_model.bin\n",
            "12/14/2019 17:06:05 - INFO - __main__ -   Namespace(device=device(type='cuda'), length=50, model_name_or_path='/content/creative-writing-with-gpt2/models/tolkien', model_type='gpt2', n_gpu=1, no_cuda=False, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n",
            "Model prompt >>> Hi my name is\n",
            "100% 50/50 [00:00<00:00, 65.10it/s]\n",
            " Lord Loudoun \n",
            "and I am come to keep you all for some night.' \n",
            "'You all belong to the Kings of Old \n",
            "And Northmen.' said Frodo, speaking of the new members of his family. \n",
            "'\n",
            "Model prompt >>> The idea behind the wisdom of our ancestors was the sword; meant for use in \n",
            "100% 50/50 [00:00<00:00, 61.17it/s]\n",
            " defence against great \n",
            "forces of evil; and it could then be employed almost entirely by any creature in the \n",
            "world that possessed the sword. It was the most of the deadly swords in antiquity, \n",
            "and they were more deadly than most\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/content/creative-writing-with-gpt2/run_generation.py\", line 256, in <module>\n",
            "    main()\n",
            "  File \"/content/creative-writing-with-gpt2/run_generation.py\", line 222, in main\n",
            "    raw_text = args.prompt if args.prompt else input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZytE1TUh-QAO",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning your own model\n",
        "\n",
        "Here we take the original GPT2 model and retrain it on a dataset of our choosing.\n",
        "\n",
        "After training the model is zipped up - you can use the *Files* tab on the right to see it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE5AynKYg5AT",
        "colab_type": "code",
        "outputId": "dfcb4176-c5df-41b7-85e7-4e56a50fbf95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "os.environ['MODELNAME'] = 'meditations'  #  change this to use a different dataset\n",
        "os.makedirs('/content/creative-writing-with-gpt2/models/{}'.format(os.environ['MODELNAME']), exist_ok=True)\n",
        "\n",
        "!python /content/creative-writing-with-gpt2/run_lm_finetuning.py \\\n",
        "  --output_dir=\"/content/creative-writing-with-gpt2/models/$MODELNAME\" \\\n",
        "  --model_type=\"bert-base-german-cased\" \\\n",
        "  --model_name_or_path=gpt2 \\\n",
        "  --do_train \\\n",
        "  --train_data_file=\"/content/creative-writing-with-gpt2/data/$MODELNAME/clean.txt\" \\\n",
        "  --num_train_epochs=4 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --per_gpu_train_batch_size 1 \\\n",
        "  --save_steps 10000\n",
        "\n",
        "%cd /content/creative-writing-with-gpt2/models/ \n",
        "!zip -r \"$MODELNAME.zip\" \"$MODELNAME\"\n",
        "%cd /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "12/14/2019 17:15:51 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/creative-writing-with-gpt2/run_lm_finetuning.py\", line 545, in <module>\n",
            "    main()\n",
            "  File \"/content/creative-writing-with-gpt2/run_lm_finetuning.py\", line 473, in main\n",
            "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
            "KeyError: 'bert-base-german-cased'\n",
            "/content/creative-writing-with-gpt2/models\n",
            "updating: meditations/ (stored 0%)\n",
            "updating: meditations/config.json (deflated 53%)\n",
            "updating: meditations/merges.txt (deflated 53%)\n",
            "updating: meditations/training_args.bin (deflated 37%)\n",
            "updating: meditations/pytorch_model.bin (deflated 16%)\n",
            "updating: meditations/tokenizer_config.json (deflated 3%)\n",
            "updating: meditations/special_tokens_map.json (deflated 52%)\n",
            "updating: meditations/added_tokens.json (stored 0%)\n",
            "updating: meditations/vocab.json (deflated 63%)\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJFcJnBwd3AY",
        "colab_type": "text"
      },
      "source": [
        "# Mounting your Google Drive\n",
        "\n",
        "After training your model you might want to save the `.zip` file - an easy way to do this is to transfer it to your Google Drive.\n",
        "\n",
        "After running the cell below, you can transfer files using the *Files* explorer on the right.\n",
        "\n",
        "You can also use your Google Drive to transfer datasets to finetune on, by putting a file `clean.txt` into the `data` folder (i.e. `creative-writing-with-gpt2/data/my_author/clean.txt`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AtCBgBwsuex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5IzTRAlmU5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}