{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonbaer/googlecolab/blob/master/EvoNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation vs. Evolutionary Strategy on GPU\n",
        "\n",
        "* Backpopragation baseline:\n",
        " * Number of epochs: 10\n",
        " * Final accuracy: 97%\n",
        " * Seconds per epoch: 9\n",
        "\n",
        "* Evolutionary Strategy:\n",
        " * Number of epochs: 10\n",
        " * Final accuracy: 90%\n",
        " * Seconds per epoch: 9\n",
        "\n",
        "**Evolutionary Strategy on CPU is much slower. This is because the loss for every individual in the population is calculated in parallel, so make sure you run this notebook on a GPU to reproduce the results.**"
      ],
      "metadata": {
        "id": "M1ZXJPcHOusB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common stuff"
      ],
      "metadata": {
        "id": "DAwHJ-rGPK3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uAO0us0-3I1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "import time\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 32\n",
        "val_batch_size = 32\n",
        "random_seed = 1337\n",
        "lr = 1E-3\n",
        "epochs = 10\n",
        "\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "val = datasets.MNIST('../data', train=False, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, pin_memory=torch.cuda.is_available())\n",
        "val_loader = torch.utils.data.DataLoader(val, val_batch_size, shuffle=False, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate(model: nn.Module):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    for input, target in val_loader:\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        output = model.forward(input)\n",
        "        loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "        pred = output.argmax(dim=-1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += input.size(0)\n",
        "\n",
        "    return loss / total, correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with Backpropagation"
      ],
      "metadata": {
        "id": "CvoTR4cnRP_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BackpropModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 64, bias=False)\n",
        "        self.fc2 = nn.Linear(64, 10, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.fc1.forward(x.flatten(1))\n",
        "        return self.fc2.forward(F.silu(x))\n",
        "\n",
        "model = BackpropModel()\n",
        "model = model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "def train_for_epoch():\n",
        "    model.train()\n",
        "    for input, target in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        output = model.forward(input)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "epoch = 0\n",
        "loss, accuracy = evaluate(model)\n",
        "print(f'epoch {epoch} | loss: {loss:.4f} | accuracy: {accuracy:.2%}')\n",
        "\n",
        "while epoch < epochs:\n",
        "    epoch += 1\n",
        "    t0 = time.time()\n",
        "    train_for_epoch()\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    dt = time.time() - t0\n",
        "    loss, accuracy = evaluate(model)\n",
        "    print(f'epoch {epoch} | loss: {loss:.4f} | accuracy: {accuracy:.2%} | seconds per epoch: {dt:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFMByA0yRO6j",
        "outputId": "1be25bc0-6a69-4d0f-e1d6-f94622573741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 | loss: 2.3049 | accuracy: 6.89%\n",
            "epoch 1 | loss: 0.1997 | accuracy: 94.11% | seconds per epoch: 8.490\n",
            "epoch 2 | loss: 0.1356 | accuracy: 95.90% | seconds per epoch: 8.893\n",
            "epoch 3 | loss: 0.1042 | accuracy: 96.85% | seconds per epoch: 8.903\n",
            "epoch 4 | loss: 0.0964 | accuracy: 97.16% | seconds per epoch: 8.888\n",
            "epoch 5 | loss: 0.0911 | accuracy: 97.19% | seconds per epoch: 8.697\n",
            "epoch 6 | loss: 0.0894 | accuracy: 97.12% | seconds per epoch: 8.677\n",
            "epoch 7 | loss: 0.0845 | accuracy: 97.48% | seconds per epoch: 9.611\n",
            "epoch 8 | loss: 0.0728 | accuracy: 97.52% | seconds per epoch: 9.800\n",
            "epoch 9 | loss: 0.0768 | accuracy: 97.68% | seconds per epoch: 8.868\n",
            "epoch 10 | loss: 0.0787 | accuracy: 97.62% | seconds per epoch: 8.842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with Evolutionary Strategy"
      ],
      "metadata": {
        "id": "P-v-NK3rRXy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 2.7E-3\n",
        "population_size = 64\n",
        "generations_per_batch = 2\n",
        "num_parents_for_mating = 4\n",
        "\n",
        "class EvoLinear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int) -> None:\n",
        "        super().__init__()\n",
        "        self.weight: torch.Tensor\n",
        "        self.register_buffer('weight', torch.zeros(out_features, in_features))\n",
        "        self.offspring: torch.Tensor | None = None\n",
        "\n",
        "    def next_generation(self, population_size: int, lr: float):\n",
        "        out_features, in_features = self.weight.size()\n",
        "        mean = self.weight.expand(population_size, 1, out_features, in_features)\n",
        "        self.offspring = torch.normal(mean, std=lr)\n",
        "\n",
        "    def mate(self, parents: list[int]):\n",
        "        self.weight = self.offspring[parents, 0, :, :].mean(0, keepdim=False)\n",
        "\n",
        "    def reset(self):\n",
        "        self.offspring = None\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        if self.offspring is not None:\n",
        "            if x.dim() == 2:\n",
        "                x = x.unsqueeze(0)\n",
        "            return torch.einsum('ebi,eboi->ebo', x, self.offspring)\n",
        "        return F.linear(x, self.weight)\n",
        "\n",
        "class EvoModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = EvoLinear(28 * 28, 64)\n",
        "        self.fc2 = EvoLinear(64, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.fc1.forward(x.flatten(1))\n",
        "        return self.fc2.forward(F.silu(x))\n",
        "\n",
        "    def next_generation(self, population_size: int, lr: float):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, EvoLinear):\n",
        "                m.next_generation(population_size, lr)\n",
        "\n",
        "    def mate(self, parents: list[int]):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, EvoLinear):\n",
        "                m.mate(parents)\n",
        "\n",
        "    def reset(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, EvoLinear):\n",
        "                m.reset()\n",
        "\n",
        "model = EvoModel()\n",
        "model = model.to(device)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evolve_for_epoch(lr: float):\n",
        "    model.eval()\n",
        "    for input, target in train_loader:\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        for _ in range(generations_per_batch):\n",
        "            model.next_generation(population_size, lr)\n",
        "            output = model.forward(input)\n",
        "            loss = F.cross_entropy(output.flatten(0, 1), target.expand(population_size, -1).flatten(), reduction='none')\n",
        "            loss = loss.unflatten(0, (population_size, target.size(0))).mean(dim=-1)\n",
        "            parents = torch.topk(loss, k=num_parents_for_mating, largest=False).indices.tolist()\n",
        "            model.mate(parents)\n",
        "\n",
        "epoch = 0\n",
        "model.reset()\n",
        "loss, accuracy = evaluate(model)\n",
        "print(f'epoch {epoch} | loss: {loss:.4f} | accuracy: {accuracy:.2%}')\n",
        "\n",
        "while epoch < epochs:\n",
        "    epoch += 1\n",
        "    t0 = time.time()\n",
        "    evolve_for_epoch(lr / epoch)\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    dt = time.time() - t0\n",
        "    model.reset()\n",
        "    loss, accuracy = evaluate(model)\n",
        "    print(f'epoch {epoch} | loss: {loss:.4f} | accuracy: {accuracy:.2%} | seconds per epoch: {dt:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx1i59UMRbJq",
        "outputId": "34a17ddf-b4fc-4d48-86e6-38c9251c3d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 | loss: 2.3026 | accuracy: 9.80%\n",
            "epoch 1 | loss: 0.4850 | accuracy: 86.40% | seconds per epoch: 8.426\n",
            "epoch 2 | loss: 0.4059 | accuracy: 88.01% | seconds per epoch: 9.119\n",
            "epoch 3 | loss: 0.3815 | accuracy: 88.97% | seconds per epoch: 8.995\n",
            "epoch 4 | loss: 0.3671 | accuracy: 89.26% | seconds per epoch: 9.017\n",
            "epoch 5 | loss: 0.3601 | accuracy: 89.43% | seconds per epoch: 9.042\n",
            "epoch 6 | loss: 0.3499 | accuracy: 89.68% | seconds per epoch: 8.669\n",
            "epoch 7 | loss: 0.3453 | accuracy: 89.84% | seconds per epoch: 8.629\n",
            "epoch 8 | loss: 0.3410 | accuracy: 89.93% | seconds per epoch: 10.034\n",
            "epoch 9 | loss: 0.3361 | accuracy: 90.14% | seconds per epoch: 9.454\n",
            "epoch 10 | loss: 0.3329 | accuracy: 90.34% | seconds per epoch: 8.972\n"
          ]
        }
      ]
    }
  ]
}