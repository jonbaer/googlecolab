{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVfo9c9QNl2H"
      },
      "source": [
        "### Step 1: Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "-KSlw7dlNl2L",
        "outputId": "b74ed70e-a1eb-4512-885a-4081221163f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: momaland in ./.venv/lib/python3.11/site-packages (0.0.2)\n",
            "Requirement already satisfied: gymnasium>=0.28 in ./.venv/lib/python3.11/site-packages (from momaland) (0.29.1)\n",
            "Requirement already satisfied: pettingzoo[butterfly,sisl] in ./.venv/lib/python3.11/site-packages (from momaland) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in ./.venv/lib/python3.11/site-packages (from momaland) (1.26.2)\n",
            "Requirement already satisfied: networkx>=3.1 in ./.venv/lib/python3.11/site-packages (from momaland) (3.2.1)\n",
            "Requirement already satisfied: sympy>=1.12 in ./.venv/lib/python3.11/site-packages (from momaland) (1.12)\n",
            "Requirement already satisfied: pygame>=2.0.1 in ./.venv/lib/python3.11/site-packages (from momaland) (2.3.0)\n",
            "Requirement already satisfied: PyOpenGL==3.1.6 in ./.venv/lib/python3.11/site-packages (from momaland) (3.1.6)\n",
            "Requirement already satisfied: PyOpenGL-accelerate>=3.1.1 in ./.venv/lib/python3.11/site-packages (from momaland) (3.1.7)\n",
            "Requirement already satisfied: pillow>=8.3.1 in ./.venv/lib/python3.11/site-packages (from momaland) (10.1.0)\n",
            "Requirement already satisfied: wandb>=0.16.1 in ./.venv/lib/python3.11/site-packages (from momaland) (0.16.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (0.0.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy>=1.12->momaland) (1.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (5.9.7)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.3.3)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (69.0.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (4.25.1)\n",
            "Requirement already satisfied: pymunk==6.2.0 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (6.2.0)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (2.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (1.11.3)\n",
            "Requirement already satisfied: cffi>1.14.0 in ./.venv/lib/python3.11/site-packages (from pymunk==6.2.0->pettingzoo[butterfly,sisl]->momaland) (1.16.0)\n",
            "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.16.1->momaland) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.16.1->momaland) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (2023.11.17)\n",
            "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>1.14.0->pymunk==6.2.0->pettingzoo[butterfly,sisl]->momaland) (2.21)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.16.1->momaland) (5.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install momaland"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq4nRwYpNl2N"
      },
      "source": [
        "### Step 2: Create an environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c6udaL-Nl2N"
      },
      "outputs": [],
      "source": [
        "from momaland.envs.multiwalker_stability import momultiwalker_stability_v0\n",
        "import numpy as np\n",
        "\n",
        "env=momultiwalker_stability_v0.env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIFF0QJ1Nl2O"
      },
      "source": [
        "### Step 3: Extract environment information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnRJFoe4Nl2O",
        "outputId": "c38d6735-ec9f-4aac-97c8-0b556cd4e11b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box(-inf, inf, (31,), float32),\n",
              " 'walker_1': Box(-inf, inf, (31,), float32),\n",
              " 'walker_2': Box(-inf, inf, (31,), float32)}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTAmAKh6Nl2P",
        "outputId": "2239b119-a25c-4004-c727-b54c8c5f51e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box(-1.0, 1.0, (4,), float32),\n",
              " 'walker_1': Box(-1.0, 1.0, (4,), float32),\n",
              " 'walker_2': Box(-1.0, 1.0, (4,), float32)}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlzUdvy8Nl2P",
        "outputId": "cc4a2b51-d1a7-42da-e8ce-d45765b362b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32),\n",
              " 'walker_1': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32),\n",
              " 'walker_2': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32)}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reward_spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T80UNaYINl2P"
      },
      "source": [
        "### Step 4.1: AEC API Demo\n",
        "Observation, rewards, termination, truncation, and info are returned by the `last()` function, as in PZ. Except the rewards are vectorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ElX5lPmNl2Q",
        "outputId": "ce05ec65-efbc-4ccf-9b6c-5e8fd3c208c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0., 0., 0.], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32)]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()\n",
        "episode_rewards = []\n",
        "for agent in env.agent_iter():\n",
        "    # the rewards are vectors!\n",
        "    observation, vec_reward, termination, truncation, info = env.last()\n",
        "    episode_rewards.append(vec_reward)\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n",
        "\n",
        "# rewards of all agents from the first step\n",
        "episode_rewards[0:len(env.possible_agents)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt4n21r8Nl2Q"
      },
      "source": [
        "### Step 4.2: Parallel API Demo\n",
        "The environment is initialized with the `parallel_env()` function. Agents `step()` all at the same time through the environment with their actions. A key difference between AEC and Parallel is that actions and observations are dictionaries in Parallel, as they are all received at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_NltZVvNl2R",
        "outputId": "931ec6ea-e6b1-4c72-c796-59d25b9443a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_0': array([0., 0., 0.]), 'agent_1': array([0., 0., 0.])}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from momaland.envs.item_gathering import moitem_gathering_v0\n",
        "\n",
        "# new parallel env\n",
        "env = moitem_gathering_v0.parallel_env()\n",
        "observations, infos = env.reset()\n",
        "episode_rewards = []\n",
        "while env.agents:\n",
        "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "    observations, vec_rewards, terminations, truncations, infos = env.step(actions)\n",
        "    episode_rewards.append(vec_rewards)\n",
        "env.close()\n",
        "\n",
        "# rewards are stored in a dictionary, can be accessed per agent\n",
        "episode_rewards[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAE0k0x1Nl2R"
      },
      "source": [
        "### Step 5: Wrappers\n",
        "On top of the native wrappers provided by MOMAland; SuperSuit and PettingZoo wrappers are also compatible with MOMAland environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GukMLNNFNl2S"
      },
      "source": [
        "#### MOMAland"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXbWL8BKNl2S",
        "outputId": "197327db-779f-4888-fcb4-2799365f7ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-1.7753998190722102, -0.9956741660833359, -6.084330405294895]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from momaland.utils.aec_wrappers import LinearizeReward, NormalizeReward\n",
        "import numpy as np\n",
        "\n",
        "env = momultiwalker_stability_v0.env()\n",
        "\n",
        "# Normalizing the reward of each agent\n",
        "for agent in env.possible_agents:\n",
        "    for idx in range(env.reward_space(agent).shape[0]):\n",
        "        env = NormalizeReward(env, agent, idx)\n",
        "\n",
        "# Making the vector reward a scalar reward to shift to single-objective multi-agent (aka PettingZoo)\n",
        "# We can assign different weights to the objectives of each agent.\n",
        "weights = {\n",
        "    \"walker_0\": np.array([0.7, 0.3]),\n",
        "    \"walker_1\": np.array([0.5, 0.5]),\n",
        "    \"walker_2\": np.array([0.2, 0.8]),\n",
        "}\n",
        "env = LinearizeReward(env, weights)\n",
        "\n",
        "# Now we are dealing with a regular PZ env\n",
        "env.reset()\n",
        "episode_rewards = []\n",
        "for agent in env.agent_iter():\n",
        "    observation, reward, termination, truncation, info = env.last()\n",
        "    episode_rewards.append(reward)\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n",
        "\n",
        "# scalarized and normalized rewards of all agents from the last step\n",
        "episode_rewards.reverse()\n",
        "episode_rewards[0:len(env.possible_agents)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqm9wRLtNl2T"
      },
      "source": [
        "#### SuperSuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_mL_4x-Nl2T",
        "outputId": "d7198138-604d-4d05-8c14-f1f6c79effcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_0': array([0.48762643, 0.48954174, 0.28093657, 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.63619226, 0.6529357 , 0.3703892 , 0.5159465 ,\n",
              "        0.66146713, 0.39128128, 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        1.        , 0.        , 0.        , 0.        ], dtype=float32),\n",
              " 'agent_1': array([0.63619226, 0.6529357 , 0.3703892 , 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.5159465 ,\n",
              "        0.66146713, 0.39128128, 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        0.        , 1.        , 0.        , 0.        ], dtype=float32),\n",
              " 'agent_2': array([0.5159465 , 0.66146713, 0.39128128, 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.63619226,\n",
              "        0.6529357 , 0.3703892 , 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        0.        , 0.        , 1.        , 0.        ], dtype=float32),\n",
              " 'agent_3': array([0.8341556 , 0.8615172 , 0.332849  , 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.63619226,\n",
              "        0.6529357 , 0.3703892 , 0.5159465 , 0.66146713, 0.39128128,\n",
              "        0.        , 0.        , 0.        , 1.        ], dtype=float32)}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from supersuit import clip_actions_v0, normalize_obs_v0, agent_indicator_v0\n",
        "from momaland.envs.crazyrl.catch import catch_v0\n",
        "# Parallel SS wrappers\n",
        "env = catch_v0.parallel_env()\n",
        "env = clip_actions_v0(env)\n",
        "env = normalize_obs_v0(env)\n",
        "env = agent_indicator_v0(env)\n",
        "\n",
        "observations, infos = env.reset()\n",
        "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "observations, vec_rewards, terminations, truncations, infos = env.step(actions)\n",
        "\n",
        "# normalized observation\n",
        "observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbvOV49sNl2U"
      },
      "source": [
        "#### PettingZoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UocaH5vHNl2U"
      },
      "outputs": [],
      "source": [
        "# AEC PZ wrappers\n",
        "from pettingzoo.utils.wrappers.clip_out_of_bounds import ClipOutOfBoundsWrapper\n",
        "env = momultiwalker_stability_v0.env()\n",
        "env = ClipOutOfBoundsWrapper(env)\n",
        "\n",
        "env.reset()\n",
        "for agent in env.agent_iter():\n",
        "    # the rewards are vectors!\n",
        "    observation, vec_reward, termination, truncation, info = env.last()\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}