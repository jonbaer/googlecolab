{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I8pUn7zZ9qR"
      },
      "source": [
        "### Step 1: Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "82HRh96kZ9qV",
        "outputId": "73693bde-0041-40c1-c506-3da95ac1b3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: momaland in ./.venv/lib/python3.11/site-packages (0.0.2)\n",
            "Requirement already satisfied: gymnasium>=0.28 in ./.venv/lib/python3.11/site-packages (from momaland) (0.29.1)\n",
            "Requirement already satisfied: pettingzoo[butterfly,sisl] in ./.venv/lib/python3.11/site-packages (from momaland) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in ./.venv/lib/python3.11/site-packages (from momaland) (1.26.2)\n",
            "Requirement already satisfied: networkx>=3.1 in ./.venv/lib/python3.11/site-packages (from momaland) (3.2.1)\n",
            "Requirement already satisfied: sympy>=1.12 in ./.venv/lib/python3.11/site-packages (from momaland) (1.12)\n",
            "Requirement already satisfied: pygame>=2.0.1 in ./.venv/lib/python3.11/site-packages (from momaland) (2.3.0)\n",
            "Requirement already satisfied: PyOpenGL==3.1.6 in ./.venv/lib/python3.11/site-packages (from momaland) (3.1.6)\n",
            "Requirement already satisfied: PyOpenGL-accelerate>=3.1.1 in ./.venv/lib/python3.11/site-packages (from momaland) (3.1.7)\n",
            "Requirement already satisfied: pillow>=8.3.1 in ./.venv/lib/python3.11/site-packages (from momaland) (10.1.0)\n",
            "Requirement already satisfied: wandb>=0.16.1 in ./.venv/lib/python3.11/site-packages (from momaland) (0.16.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in ./.venv/lib/python3.11/site-packages (from gymnasium>=0.28->momaland) (0.0.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy>=1.12->momaland) (1.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (5.9.7)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.3.3)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (69.0.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./.venv/lib/python3.11/site-packages (from wandb>=0.16.1->momaland) (4.25.1)\n",
            "Requirement already satisfied: pymunk==6.2.0 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (6.2.0)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (2.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.11/site-packages (from pettingzoo[butterfly,sisl]->momaland) (1.11.3)\n",
            "Requirement already satisfied: cffi>1.14.0 in ./.venv/lib/python3.11/site-packages (from pymunk==6.2.0->pettingzoo[butterfly,sisl]->momaland) (1.16.0)\n",
            "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.16.1->momaland) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.16.1->momaland) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb>=0.16.1->momaland) (2023.11.17)\n",
            "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>1.14.0->pymunk==6.2.0->pettingzoo[butterfly,sisl]->momaland) (2.21)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.16.1->momaland) (5.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install momaland"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eshw8cEBZ9qX"
      },
      "source": [
        "### Step 2: Create an environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUbI3YdJZ9qY"
      },
      "outputs": [],
      "source": [
        "from momaland.envs.multiwalker import momultiwalker_v0\n",
        "import numpy as np\n",
        "\n",
        "env=momultiwalker_v0.env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlJmanv1Z9qY"
      },
      "source": [
        "### Step 3: Extract environment information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyXmL90_Z9qZ",
        "outputId": "be6ac2a4-d525-4098-d8e0-d2c7130cc338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box(-inf, inf, (31,), float32),\n",
              " 'walker_1': Box(-inf, inf, (31,), float32),\n",
              " 'walker_2': Box(-inf, inf, (31,), float32)}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk-A5Rs9Z9qZ",
        "outputId": "243b6be8-746f-44b0-a717-e7068a380979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box(-1.0, 1.0, (4,), float32),\n",
              " 'walker_1': Box(-1.0, 1.0, (4,), float32),\n",
              " 'walker_2': Box(-1.0, 1.0, (4,), float32)}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLBzXvfvZ9qa",
        "outputId": "fbc4227a-27a8-4529-fb43-36389c6173dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'walker_0': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32),\n",
              " 'walker_1': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32),\n",
              " 'walker_2': Box([  -0.46666667 -110.         -100.        ], [0.46666667 0.         0.        ], (3,), float32)}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reward_spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bktnczxZ9qa"
      },
      "source": [
        "### Step 4.1: AEC API Demo\n",
        "Observation, rewards, termination, truncation, and info are returned by the `last()` function, as in PZ. Except the rewards are vectorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoMBaZzcZ9qb",
        "outputId": "bf0a92a3-c679-444f-cfe9-660c3722dfc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0., 0., 0.], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32)]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()\n",
        "episode_rewards = []\n",
        "for agent in env.agent_iter():\n",
        "    # the rewards are vectors!\n",
        "    observation, vec_reward, termination, truncation, info = env.last()\n",
        "    episode_rewards.append(vec_reward)\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n",
        "\n",
        "# rewards of all agents from the first step\n",
        "episode_rewards[0:len(env.possible_agents)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJmQWculZ9qb"
      },
      "source": [
        "### Step 4.2: Parallel API Demo\n",
        "The environment is initialized with the `parallel_env()` function. Agents `step()` all at the same time through the environment with their actions. A key difference between AEC and Parallel is that actions and observations are dictionaries in Parallel, as they are all received at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfcvyLsTZ9qc",
        "outputId": "08a310f3-25db-46b7-b2c0-a8b35b315767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_0': array([0., 0., 0.]), 'agent_1': array([0., 0., 0.])}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from momaland.envs.item_gathering import moitem_gathering_v0\n",
        "\n",
        "# new parallel env\n",
        "env = moitem_gathering_v0.parallel_env()\n",
        "observations, infos = env.reset()\n",
        "episode_rewards = []\n",
        "while env.agents:\n",
        "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "    observations, vec_rewards, terminations, truncations, infos = env.step(actions)\n",
        "    episode_rewards.append(vec_rewards)\n",
        "env.close()\n",
        "\n",
        "# rewards are stored in a dictionary, can be accessed per agent\n",
        "episode_rewards[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxCnmsFaZ9qc"
      },
      "source": [
        "### Step 5: Wrappers\n",
        "On top of the native wrappers provided by MOMAland; SuperSuit and PettingZoo wrappers are also compatible with MOMAland environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXBb84tCZ9qd"
      },
      "source": [
        "#### MOMAland"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7ZwSE0-Z9qd",
        "outputId": "7d19a65c-7226-47b8-9a07-0871a54b87cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-1.7753998190722102, -0.9956741660833359, -6.084330405294895]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from momaland.utils.aec_wrappers import LinearizeReward, NormalizeReward\n",
        "import numpy as np\n",
        "\n",
        "env = momultiwalker_v0.env()\n",
        "\n",
        "# Normalizing the reward of each agent\n",
        "for agent in env.possible_agents:\n",
        "    for idx in range(env.reward_space(agent).shape[0]):\n",
        "        env = NormalizeReward(env, agent, idx)\n",
        "\n",
        "# Making the vector reward a scalar reward to shift to single-objective multi-agent (aka PettingZoo)\n",
        "# We can assign different weights to the objectives of each agent.\n",
        "weights = {\n",
        "    \"walker_0\": np.array([0.1, 0.7, 0.2]),\n",
        "    \"walker_1\": np.array([0.6, 0.1, 0.3]),\n",
        "    \"walker_2\": np.array([0.2, 0.2, 0.6]),\n",
        "}\n",
        "env = LinearizeReward(env, weights)\n",
        "\n",
        "# Now we are dealing with a regular PZ env\n",
        "env.reset()\n",
        "episode_rewards = []\n",
        "for agent in env.agent_iter():\n",
        "    observation, reward, termination, truncation, info = env.last()\n",
        "    episode_rewards.append(reward)\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n",
        "\n",
        "# scalarized and normalized rewards of all agents from the last step\n",
        "episode_rewards.reverse()\n",
        "episode_rewards[0:len(env.possible_agents)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8RJ8F5DZ9qe"
      },
      "source": [
        "#### SuperSuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFd2QyJTZ9qe",
        "outputId": "3620a529-b5eb-4147-82b0-abd98e34f578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_0': array([0.48762643, 0.48954174, 0.28093657, 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.63619226, 0.6529357 , 0.3703892 , 0.5159465 ,\n",
              "        0.66146713, 0.39128128, 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        1.        , 0.        , 0.        , 0.        ], dtype=float32),\n",
              " 'agent_1': array([0.63619226, 0.6529357 , 0.3703892 , 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.5159465 ,\n",
              "        0.66146713, 0.39128128, 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        0.        , 1.        , 0.        , 0.        ], dtype=float32),\n",
              " 'agent_2': array([0.5159465 , 0.66146713, 0.39128128, 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.63619226,\n",
              "        0.6529357 , 0.3703892 , 0.8341556 , 0.8615172 , 0.332849  ,\n",
              "        0.        , 0.        , 1.        , 0.        ], dtype=float32),\n",
              " 'agent_3': array([0.8341556 , 0.8615172 , 0.332849  , 0.66940665, 0.6666667 ,\n",
              "        0.86621314, 0.48762643, 0.48954174, 0.28093657, 0.63619226,\n",
              "        0.6529357 , 0.3703892 , 0.5159465 , 0.66146713, 0.39128128,\n",
              "        0.        , 0.        , 0.        , 1.        ], dtype=float32)}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from supersuit import clip_actions_v0, normalize_obs_v0, agent_indicator_v0\n",
        "from momaland.envs.crazyrl.catch import catch_v0\n",
        "# Parallel SS wrappers\n",
        "env = catch_v0.parallel_env()\n",
        "env = clip_actions_v0(env)\n",
        "env = normalize_obs_v0(env)\n",
        "env = agent_indicator_v0(env)\n",
        "\n",
        "observations, infos = env.reset()\n",
        "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "observations, vec_rewards, terminations, truncations, infos = env.step(actions)\n",
        "\n",
        "# normalized observation\n",
        "observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7K1cqcwZ9qf"
      },
      "source": [
        "#### PettingZoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRjiz3ytZ9qf"
      },
      "outputs": [],
      "source": [
        "# AEC PZ wrappers\n",
        "from pettingzoo.utils.wrappers.clip_out_of_bounds import ClipOutOfBoundsWrapper\n",
        "env = momultiwalker_v0.env()\n",
        "env = ClipOutOfBoundsWrapper(env)\n",
        "\n",
        "env.reset()\n",
        "for agent in env.agent_iter():\n",
        "    # the rewards are vectors!\n",
        "    observation, vec_reward, termination, truncation, info = env.last()\n",
        "    if termination or truncation:\n",
        "        action = None\n",
        "    else:\n",
        "        action = env.action_space(agent).sample()\n",
        "    env.step(action)\n",
        "env.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}